{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw the typical supervised learning model was unable to predict fraud providers effectively I am going to try Neural network in this notebook.\n",
    "\n",
    "We believe that deep learning is an important area of research that will play a critical role in the future of modeling class-imbalanced big data. Over the last 10 years, deep learning methods have grown in popularity as they have improved the state-of-the-art in speech recognition, computer vision, and other domains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix, classification_report, \\\n",
    "recall_score, precision_score, accuracy_score, plot_confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "import os\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading our ckeaned and final data for modeling process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"./datasets/final_data.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For modeling, as we know we can not add categorical column so I am selecting numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['total_drug_cost', 'total_claim_count', 'total_day_supply',\n",
    "       'Opioid Claim Count', 'Opioid Prescribing Rate',\n",
    "       'Long-Acting Opioid Claim Count', 'Long-Acting Opioid Prescribing Rate',\n",
    "       'Total_Payment_Sum', 'Number of Suppliers',\n",
    "       'Number of Supplier Beneficiaries', 'Number of Supplier Claims',\n",
    "       'Average Supplier Submitted Charge',\n",
    "       'Average Supplier Medicare Allow Amount',\n",
    "       'Average Supplier Medicare Payment Amount',\n",
    "       'Average Supplier Medicare Standard Amount', 'is_fraud']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spilliting the dataset as train, test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a utility from sklearn to split and shuffle our dataset.\n",
    "X_train, X_test = train_test_split(X, test_size=0.25)\n",
    "\n",
    "# split the validation data from train data\n",
    "X_train, X_val = train_test_split(X_train, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we know, we do not need our target variable is \"is_fraud\". Let's extract target variable from X_train, X_test and X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form np arrays of labels and features.\n",
    "\n",
    "train_labels = np.array(X_train.pop('is_fraud'))\n",
    "bool_train_labels = train_labels != 0\n",
    "val_labels = np.array(X_val.pop('is_fraud'))\n",
    "test_labels = np.array(X_test.pop('is_fraud'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making our datasets as an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "X_test = np.array(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the input features using the sklearn StandardScaler. This will set the mean to 0 and standard deviation to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "\n",
    "X_val = ss.transform(X_val)\n",
    "X_test = ss.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100174, 15), (44523, 15), (33392, 15))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking shape of X_train, X_test, X_val\n",
    "\n",
    "\n",
    "X_train.shape,X_test.shape,X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100174,), (33392,), (44523,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the shape of \n",
    "\n",
    "train_labels.shape,val_labels.shape,test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking 0 and 1 in my target variable\n",
    "\n",
    "neg, pos = np.bincount(df['is_fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177973, 116)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg, pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I am setting all my matrices that I will require to evaluate my model in one list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am making one function in which will perform my modeling with two hiden layer and early stopping as my \n",
    "regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(metrics = METRICS, output_bias=None):\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "         #Intantiate the model\n",
    "            \n",
    "    model = keras.Sequential([\n",
    "             keras.layers.Dense(\n",
    "               64, activation='relu',\n",
    "               input_shape=(X_train.shape[-1],)),\n",
    "            keras.layers.Dropout(0.5),\n",
    "\n",
    "        keras.layers.Dense(\n",
    "          32, activation='relu'),      #adding hidden layer\n",
    "          \n",
    "      keras.layers.Dropout(0.5),\n",
    "        \n",
    "         keras.layers.Dense(           #adding hidden layer\n",
    "          16, activation='relu'),\n",
    "          \n",
    "      keras.layers.Dropout(0.5),\n",
    "        \n",
    "      keras.layers.Dense(1, activation='sigmoid',             #output layer\n",
    "                         bias_initializer=output_bias),\n",
    "  ])\n",
    "\n",
    "    model.compile(\n",
    "      optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "      loss=keras.losses.BinaryCrossentropy(),\n",
    "      metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am setting 500 epochs and 8192 batch size so that it can detect more frauds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 500\n",
    "BATCH_SIZE = 8192\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_auc', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=make_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 64)                1024      \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,649\n",
      "Trainable params: 3,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive and negative features\n",
    "\n",
    "pos_features = X_train[bool_train_labels]\n",
    "neg_features = X_train[~bool_train_labels]\n",
    "\n",
    "# Positive and negative labes(target variable)\n",
    "\n",
    "pos_labels = train_labels[bool_train_labels]\n",
    "neg_labels = train_labels[~bool_train_labels]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we know our data is highly imbalance so I am going to resample my minority class.I am randomly increasing my minority class using np.random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100113, 15)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = np.arange(len(pos_features))\n",
    "choices = np.random.choice(ids, len(neg_features))\n",
    "\n",
    "# resamples positive features and positive labels\n",
    "\n",
    "res_pos_features = pos_features[choices]\n",
    "res_pos_labels = pos_labels[choices]\n",
    "\n",
    "res_pos_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concating the resampled poditive and negative features as well as the resampled positive and negative lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatig the resampled positive and negative features and labels\n",
    "\n",
    "X_res = np.concatenate([res_pos_features, neg_features], axis=0)\n",
    "label_res = np.concatenate([res_pos_labels, neg_labels], axis=0)\n",
    "\n",
    "order = np.arange(len(label_res))\n",
    "np.random.shuffle(order)\n",
    "X_res = X_res[order]\n",
    "label_res = label_res[order]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're using tf.data the easiest way to produce balanced examples is to start with a positive and a negative dataset, and merge them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 150000\n",
    "def make_ds(features, labels):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((features, labels))#.cache()\n",
    "    ds = ds.shuffle(BUFFER_SIZE).repeat()\n",
    "    return ds\n",
    "\n",
    "pos_ds = make_ds(pos_features, pos_labels)\n",
    "neg_ds = make_ds(neg_features, neg_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_ds = tf.data.experimental.sample_from_datasets([pos_ds, neg_ds], weights=[0.5, 0.5])\n",
    "resampled_ds = resampled_ds.batch(BATCH_SIZE).prefetch(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps per epoch the number of batches required to see each negative example once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_steps_per_epoch = np.ceil(2.0*(neg)/BATCH_SIZE)\n",
    "resampled_steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "44/44 [==============================] - 4s 100ms/step - loss: 0.7166 - tp: 98379.0000 - fp: 90783.0000 - tn: 89234.0000 - fn: 82052.0000 - accuracy: 0.5205 - precision: 0.5201 - recall: 0.5452 - auc: 0.5339 - val_loss: 0.7108 - val_tp: 14.0000 - val_fp: 28700.0000 - val_tn: 4675.0000 - val_fn: 3.0000 - val_accuracy: 0.1404 - val_precision: 4.8757e-04 - val_recall: 0.8235 - val_auc: 0.5444\n",
      "Epoch 2/500\n",
      "44/44 [==============================] - 3s 76ms/step - loss: 0.6737 - tp: 107430.0000 - fp: 86152.0000 - tn: 94052.0000 - fn: 72814.0000 - accuracy: 0.5590 - precision: 0.5550 - recall: 0.5960 - auc: 0.5983 - val_loss: 0.6791 - val_tp: 6.0000 - val_fp: 9932.0000 - val_tn: 23443.0000 - val_fn: 11.0000 - val_accuracy: 0.7022 - val_precision: 6.0374e-04 - val_recall: 0.3529 - val_auc: 0.5146\n",
      "Epoch 3/500\n",
      "44/44 [==============================] - 3s 78ms/step - loss: 0.6446 - tp: 94318.0000 - fp: 54861.0000 - tn: 125267.0000 - fn: 86002.0000 - accuracy: 0.6092 - precision: 0.6322 - recall: 0.5231 - auc: 0.6617 - val_loss: 0.6224 - val_tp: 5.0000 - val_fp: 7235.0000 - val_tn: 26140.0000 - val_fn: 12.0000 - val_accuracy: 0.7830 - val_precision: 6.9061e-04 - val_recall: 0.2941 - val_auc: 0.5400\n",
      "Epoch 4/500\n",
      "44/44 [==============================] - 3s 76ms/step - loss: 0.6105 - tp: 103119.0000 - fp: 48346.0000 - tn: 131701.0000 - fn: 77282.0000 - accuracy: 0.6515 - precision: 0.6808 - recall: 0.5716 - auc: 0.7200 - val_loss: 0.5644 - val_tp: 5.0000 - val_fp: 7091.0000 - val_tn: 26284.0000 - val_fn: 12.0000 - val_accuracy: 0.7873 - val_precision: 7.0462e-04 - val_recall: 0.2941 - val_auc: 0.5676\n",
      "Epoch 5/500\n",
      "44/44 [==============================] - 3s 76ms/step - loss: 0.5766 - tp: 114856.0000 - fp: 49091.0000 - tn: 131326.0000 - fn: 65175.0000 - accuracy: 0.6830 - precision: 0.7006 - recall: 0.6380 - auc: 0.7626 - val_loss: 0.5212 - val_tp: 6.0000 - val_fp: 7174.0000 - val_tn: 26201.0000 - val_fn: 11.0000 - val_accuracy: 0.7848 - val_precision: 8.3565e-04 - val_recall: 0.3529 - val_auc: 0.5434\n",
      "Epoch 6/500\n",
      "44/44 [==============================] - 4s 80ms/step - loss: 0.5421 - tp: 125590.0000 - fp: 48860.0000 - tn: 131767.0000 - fn: 54231.0000 - accuracy: 0.7140 - precision: 0.7199 - recall: 0.6984 - auc: 0.7994 - val_loss: 0.4790 - val_tp: 5.0000 - val_fp: 7177.0000 - val_tn: 26198.0000 - val_fn: 12.0000 - val_accuracy: 0.7847 - val_precision: 6.9618e-04 - val_recall: 0.2941 - val_auc: 0.5224\n",
      "Epoch 7/500\n",
      "44/44 [==============================] - 4s 80ms/step - loss: 0.5085 - tp: 134605.0000 - fp: 47560.0000 - tn: 132974.0000 - fn: 45309.0000 - accuracy: 0.7424 - precision: 0.7389 - recall: 0.7482 - auc: 0.8292 - val_loss: 0.4340 - val_tp: 5.0000 - val_fp: 6425.0000 - val_tn: 26950.0000 - val_fn: 12.0000 - val_accuracy: 0.8072 - val_precision: 7.7760e-04 - val_recall: 0.2941 - val_auc: 0.5129\n",
      "Epoch 8/500\n",
      "44/44 [==============================] - 4s 80ms/step - loss: 0.4722 - tp: 143305.0000 - fp: 45161.0000 - tn: 134706.0000 - fn: 37276.0000 - accuracy: 0.7713 - precision: 0.7604 - recall: 0.7936 - auc: 0.8568 - val_loss: 0.3832 - val_tp: 3.0000 - val_fp: 5251.0000 - val_tn: 28124.0000 - val_fn: 14.0000 - val_accuracy: 0.8423 - val_precision: 5.7099e-04 - val_recall: 0.1765 - val_auc: 0.5131\n",
      "Epoch 9/500\n",
      "44/44 [==============================] - 4s 80ms/step - loss: 0.4381 - tp: 148654.0000 - fp: 41433.0000 - tn: 138511.0000 - fn: 31850.0000 - accuracy: 0.7967 - precision: 0.7820 - recall: 0.8235 - auc: 0.8792 - val_loss: 0.3483 - val_tp: 2.0000 - val_fp: 4735.0000 - val_tn: 28640.0000 - val_fn: 15.0000 - val_accuracy: 0.8578 - val_precision: 4.2221e-04 - val_recall: 0.1176 - val_auc: 0.5024\n",
      "Epoch 10/500\n",
      "44/44 [==============================] - 3s 79ms/step - loss: 0.4054 - tp: 153450.0000 - fp: 38155.0000 - tn: 141901.0000 - fn: 26942.0000 - accuracy: 0.8194 - precision: 0.8009 - recall: 0.8506 - auc: 0.8981 - val_loss: 0.3357 - val_tp: 4.0000 - val_fp: 5171.0000 - val_tn: 28204.0000 - val_fn: 13.0000 - val_accuracy: 0.8448 - val_precision: 7.7295e-04 - val_recall: 0.2353 - val_auc: 0.4974\n",
      "Epoch 11/500\n",
      "44/44 [==============================] - 4s 80ms/step - loss: 0.3779 - tp: 156614.0000 - fp: 35433.0000 - tn: 145093.0000 - fn: 23308.0000 - accuracy: 0.8370 - precision: 0.8155 - recall: 0.8705 - auc: 0.9118 - val_loss: 0.3027 - val_tp: 3.0000 - val_fp: 4527.0000 - val_tn: 28848.0000 - val_fn: 14.0000 - val_accuracy: 0.8640 - val_precision: 6.6225e-04 - val_recall: 0.1765 - val_auc: 0.4873\n",
      "Epoch 12/500\n",
      "44/44 [==============================] - 3s 78ms/step - loss: 0.3550 - tp: 159903.0000 - fp: 33277.0000 - tn: 147033.0000 - fn: 20235.0000 - accuracy: 0.8515 - precision: 0.8277 - recall: 0.8877 - auc: 0.9221 - val_loss: 0.2662 - val_tp: 3.0000 - val_fp: 3812.0000 - val_tn: 29563.0000 - val_fn: 14.0000 - val_accuracy: 0.8854 - val_precision: 7.8637e-04 - val_recall: 0.1765 - val_auc: 0.4785\n",
      "Epoch 13/500\n",
      "44/44 [==============================] - 4s 82ms/step - loss: 0.3302 - tp: 162534.0000 - fp: 30912.0000 - tn: 149214.0000 - fn: 17788.0000 - accuracy: 0.8649 - precision: 0.8402 - recall: 0.9014 - auc: 0.9325 - val_loss: 0.2571 - val_tp: 3.0000 - val_fp: 3844.0000 - val_tn: 29531.0000 - val_fn: 14.0000 - val_accuracy: 0.8845 - val_precision: 7.7983e-04 - val_recall: 0.1765 - val_auc: 0.4682\n",
      "Epoch 14/500\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.3129 - tp: 163428.0000 - fp: 28806.0000 - tn: 152015.0000 - fn: 16199.0000 - accuracy: 0.8751 - precision: 0.8502 - recall: 0.9098 - auc: 0.9391Restoring model weights from the end of the best epoch.\n",
      "44/44 [==============================] - 4s 80ms/step - loss: 0.3129 - tp: 163428.0000 - fp: 28806.0000 - tn: 152015.0000 - fn: 16199.0000 - accuracy: 0.8751 - precision: 0.8502 - recall: 0.9098 - auc: 0.9391 - val_loss: 0.2451 - val_tp: 3.0000 - val_fp: 3688.0000 - val_tn: 29687.0000 - val_fn: 14.0000 - val_accuracy: 0.8891 - val_precision: 8.1279e-04 - val_recall: 0.1765 - val_auc: 0.4723\n",
      "Epoch 00014: early stopping\n"
     ]
    }
   ],
   "source": [
    "resampled_model = make_model()\n",
    "\n",
    "\n",
    "# Reset the bias to zero, since this dataset is balanced.\n",
    "output_layer = resampled_model.layers[-1] \n",
    "output_layer.bias.assign([0])\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, val_labels)).cache()\n",
    "val_ds = val_ds.batch(BATCH_SIZE).prefetch(2) \n",
    "\n",
    "resampled_history = resampled_model.fit(\n",
    "    resampled_ds,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=resampled_steps_per_epoch,\n",
    "    callbacks = [early_stopping],\n",
    "    validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = resampled_model.predict(X_train, batch_size=BATCH_SIZE)\n",
    "test_pred = resampled_model.predict(X_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.49872449040412903\n",
      "tp :  13.0\n",
      "fp :  9396.0\n",
      "tn :  35089.0\n",
      "fn :  25.0\n",
      "accuracy :  0.7884014844894409\n",
      "precision :  0.0013816558057442307\n",
      "recall :  0.34210526943206787\n",
      "auc :  0.6408461332321167\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resampled_results = resampled_model.evaluate(X_test, test_labels,\n",
    "                                             batch_size=BATCH_SIZE, verbose=0)\n",
    "for name, value in zip(resampled_model.metrics_names, resampled_results):\n",
    "    print(name, ': ', value)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, p=0.5):\n",
    "    cm = confusion_matrix(labels, predictions > p)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.title('Confusion matrix'.format(p))\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    print('Legitimate medicare provider Detected (True Negatives): ', cm[0][0])\n",
    "    print('Legitimate medicare provider Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "    print('Fraudulent medicare provider Missed (False Negatives): ', cm[1][0])\n",
    "    print('Fraudulent medicare provider Detected (True Positives): ', cm[1][1])\n",
    "    print('Total Fraudulent provider: ', np.sum(cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legitimate medicare provider Detected (True Negatives):  35089\n",
      "Legitimate medicare provider Incorrectly Detected (False Positives):  9396\n",
      "Fraudulent medicare provider Missed (False Negatives):  25\n",
      "Fraudulent medicare provider Detected (True Positives):  13\n",
      "Total Fraudulent provider:  38\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cm(test_labels, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see that, there are only 25 false negative which is good compared to other models \n",
    "we performed before. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model detect 13 correct frauds and 35089 non fraud provider. It predicted 9396 fraud providers who are not fraud. Our recall score is 0.34 so it is saying that my model is 34% correctly identify the frauds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we know our class is highly imbalance so it is difficult to detect frauds from very low amout of previously detected \n",
    "fraud providers and in my excluded providers data there are more than 50000 missing NPI who are actual \n",
    "fraud providers. So In future I will gather mpore data and looking for that NPI in NPI registery website and will try to predict\n",
    "the actual frauds.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "credit : https://www.tensorflow.org/tutorials/structured_data/imbalanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
